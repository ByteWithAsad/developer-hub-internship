{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b2411a6-3305-4e1c-a908-d1ef06dd5fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1795 images belonging to 9 classes.\n",
      "Found 444 images belonging to 9 classes.\n",
      "Found 118 images belonging to 9 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m216s\u001b[0m 2s/step - accuracy: 0.1993 - loss: 2.1151 - val_accuracy: 0.2140 - val_loss: 2.0291\n",
      "Epoch 2/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 2s/step - accuracy: 0.2008 - loss: 2.0263 - val_accuracy: 0.2027 - val_loss: 2.0209\n",
      "Epoch 3/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 2s/step - accuracy: 0.2044 - loss: 2.0225 - val_accuracy: 0.1959 - val_loss: 2.0424\n",
      "Epoch 4/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 2s/step - accuracy: 0.2118 - loss: 2.0398 - val_accuracy: 0.1577 - val_loss: 2.0340\n",
      "Epoch 5/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 2s/step - accuracy: 0.1974 - loss: 2.0446 - val_accuracy: 0.2072 - val_loss: 2.0461\n",
      "Epoch 6/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 2s/step - accuracy: 0.1982 - loss: 2.0525 - val_accuracy: 0.2005 - val_loss: 2.0229\n",
      "Epoch 7/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.1829 - loss: 2.0501 - val_accuracy: 0.2027 - val_loss: 2.0204\n",
      "Epoch 8/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.1750 - loss: 2.0423 - val_accuracy: 0.2140 - val_loss: 2.0364\n",
      "Epoch 9/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 2s/step - accuracy: 0.1935 - loss: 2.0458 - val_accuracy: 0.2140 - val_loss: 2.0131\n",
      "Epoch 10/10\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 2s/step - accuracy: 0.2032 - loss: 2.0258 - val_accuracy: 0.1982 - val_loss: 2.0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.1189 - loss: 2.4298\n",
      "Test Accuracy: 0.18644067645072937\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001B0A2B8E3E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001B0A2B8E3E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 3s/step\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "         actinic keratosis       0.00      0.00      0.00        16\n",
      "      basal cell carcinoma       0.00      0.00      0.00        16\n",
      "            dermatofibroma       0.00      0.00      0.00        16\n",
      "                  melanoma       0.75      0.19      0.30        16\n",
      "                     nevus       0.16      0.94      0.27        16\n",
      "pigmented benign keratosis       0.22      0.25      0.24        16\n",
      "      seborrheic keratosis       0.00      0.00      0.00         3\n",
      "   squamous cell carcinoma       0.00      0.00      0.00        16\n",
      "           vascular lesion       0.00      0.00      0.00         3\n",
      "\n",
      "                  accuracy                           0.19       118\n",
      "                 macro avg       0.13      0.15      0.09       118\n",
      "              weighted avg       0.15      0.19      0.11       118\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF Report saved at: C:\\Users\\USER\\OneDrive\\Desktop\\Developer Hub Internship\\Task3\\skin_cancer_report.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from fpdf import FPDF\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "base_dir = r\"C:\\Users\\USER\\OneDrive\\Desktop\\Developer Hub Internship\\Task3\\Skin cancer\\Dataset\\skin cancer\\Skin cancer ISIC The International Skin Imaging Collaboration\"\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "test_dir = os.path.join(base_dir, \"test\")\n",
    "\n",
    "img_size = (224, 224)\n",
    "batch_size = 16\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"training\"\n",
    ")\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\"\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation=\"relu\")(x)\n",
    "predictions = Dense(train_generator.num_classes, activation=\"softmax\")(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator\n",
    ")\n",
    "\n",
    "model_save_path = r\"C:\\Users\\USER\\OneDrive\\Desktop\\Developer Hub Internship\\Task3\\skin_cancer_model.h5\"\n",
    "history_path = r\"C:\\Users\\USER\\OneDrive\\Desktop\\Developer Hub Internship\\Task3\\skin_cancer_history.pkl\"\n",
    "model.save(model_save_path)\n",
    "with open(history_path, \"wb\") as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(\"Test Accuracy:\", test_acc)\n",
    "\n",
    "y_true = test_generator.classes\n",
    "y_pred_prob = model.predict(test_generator)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "target_names = list(test_generator.class_indices.keys())\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=target_names, yticklabels=target_names, cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix - Skin Cancer\")\n",
    "cm_image_path = r\"C:\\Users\\USER\\OneDrive\\Desktop\\Developer Hub Internship\\Task3\\cm_skin.png\"\n",
    "plt.savefig(cm_image_path)\n",
    "plt.close()\n",
    "\n",
    "y_true_bin = label_binarize(y_true, classes=np.arange(len(target_names)))\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(len(target_names)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_pred_prob[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "plt.figure(figsize=(8,6))\n",
    "for i in range(len(target_names)):\n",
    "    plt.plot(fpr[i], tpr[i], label=f\"{target_names[i]} (AUC = {roc_auc[i]:.2f})\")\n",
    "plt.plot([0,1], [0,1], \"k--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve - Skin Cancer\")\n",
    "plt.legend()\n",
    "roc_image_path = r\"C:\\Users\\USER\\OneDrive\\Desktop\\Developer Hub Internship\\Task3\\roc_skin.png\"\n",
    "plt.savefig(roc_image_path)\n",
    "plt.close()\n",
    "\n",
    "history_path = r\"C:\\Users\\USER\\OneDrive\\Desktop\\Developer Hub Internship\\Task3\\skin_cancer_history.pkl\"\n",
    "with open(history_path, \"rb\") as f:\n",
    "    history = pickle.load(f)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history[\"accuracy\"], label=\"Train Acc\")\n",
    "plt.plot(history[\"val_accuracy\"], label=\"Val Acc\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "acc_image_path = r\"C:\\Users\\USER\\OneDrive\\Desktop\\Developer Hub Internship\\Task3\\acc_skin.png\"\n",
    "plt.savefig(acc_image_path)\n",
    "plt.close()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history[\"loss\"], label=\"Train Loss\")\n",
    "plt.plot(history[\"val_loss\"], label=\"Val Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "loss_image_path = r\"C:\\Users\\USER\\OneDrive\\Desktop\\Developer Hub Internship\\Task3\\loss_skin.png\"\n",
    "plt.savefig(loss_image_path)\n",
    "plt.close()\n",
    "\n",
    "pdf_save_path = r\"C:\\Users\\USER\\OneDrive\\Desktop\\Developer Hub Internship\\Task3\\skin_cancer_report.pdf\"\n",
    "pdf = FPDF()\n",
    "pdf.add_page()\n",
    "pdf.set_font(\"Arial\", 'B', 16)\n",
    "pdf.cell(0, 10, \"Skin Cancer Detection Report\", ln=True, align=\"C\")\n",
    "pdf.ln(10)\n",
    "pdf.set_font(\"Arial\", '', 12)\n",
    "pdf.multi_cell(0, 6, \"Objective:\\nThe objective is to develop a ResNet50-based model to classify dermoscopic images of skin cancer into multiple categories.\")\n",
    "pdf.ln(5)\n",
    "pdf.multi_cell(0, 6, f\"Test Accuracy: {test_acc:.2f}\")\n",
    "pdf.ln(10)\n",
    "pdf.set_font(\"Arial\", 'B', 14)\n",
    "pdf.cell(0, 10, \"Training and Validation Accuracy\", ln=True)\n",
    "pdf.image(acc_image_path, w=150)\n",
    "pdf.ln(10)\n",
    "pdf.cell(0, 10, \"Training and Validation Loss\", ln=True)\n",
    "pdf.image(loss_image_path, w=150)\n",
    "pdf.ln(10)\n",
    "pdf.cell(0, 10, \"Confusion Matrix\", ln=True)\n",
    "pdf.image(cm_image_path, w=150)\n",
    "pdf.ln(10)\n",
    "pdf.cell(0, 10, \"ROC Curves\", ln=True)\n",
    "pdf.image(roc_image_path, w=150)\n",
    "pdf.output(pdf_save_path)\n",
    "print(\"PDF Report saved at:\", pdf_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae306e3-a9a4-4ddd-9337-7fef14f5cecb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
